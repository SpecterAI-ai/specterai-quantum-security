{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7af201",
   "metadata": {},
   "source": [
    "# Code Example 2 — Quantum-Enhanced Enumeration (Certainty Compression)\n",
    "\n",
    "This notebook models how a *quantum-augmented* approach can compress uncertainty faster than a classical enumeration baseline.\n",
    "\n",
    "We do **not** implement an exploit.\n",
    "We model exploitation as a hidden-state identification problem:\n",
    "\n",
    "- There is a correct internal state `s*` among `N` candidates.\n",
    "- Each query provides noisy evidence about which candidate is correct.\n",
    "- A classical attacker aggregates evidence gradually.\n",
    "- A quantum-augmented attacker uses an \"amplification\" step that boosts the correct candidate's weight.\n",
    "\n",
    "The amplification step here is a numerical analogue of amplitude amplification / optimal decision acceleration.\n",
    "It is a controlled abstraction used for threat modeling, and it produces a clear, printable comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11b33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145289a6",
   "metadata": {},
   "source": [
    "## Parameters (Matched to Code Example 1)\n",
    "\n",
    "We keep the same high-level setting as the classical baseline:\n",
    "\n",
    "- `N`: number of candidate internal states\n",
    "- `μ_good - μ_bad`: separation between correct and incorrect candidates\n",
    "- `σ`: noise level\n",
    "- `target_confidence`: stopping threshold\n",
    "- `anomaly_query_threshold`: illustrative \"too many queries becomes noticeable\" threshold\n",
    "\n",
    "We will compare:\n",
    "- median queries to reach target confidence\n",
    "- success rate\n",
    "- fraction exceeding anomaly threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4628d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "N = 128\n",
    "mu_good = 1.0\n",
    "mu_bad  = 0.0\n",
    "sigma   = 1.0\n",
    "\n",
    "max_queries = 200\n",
    "trials = 200\n",
    "\n",
    "target_confidence = 0.95\n",
    "anomaly_query_threshold = 80\n",
    "\n",
    "# Quantum-analogue amplification strength (tuneable)\n",
    "# Higher => fewer queries needed, but still bounded by noise.\n",
    "amplify_strength = 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f0218",
   "metadata": {},
   "source": [
    "## Score Sampling\n",
    "\n",
    "We use the same score-generation model as the classical baseline:\n",
    "\n",
    "Each query produces noisy scores for all candidates.\n",
    "The correct candidate has a slightly higher expected score.\n",
    "\n",
    "This represents any weak side-information channel that improves inference:\n",
    "timing differences, parsing behaviors, error patterns, response shapes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8176687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_scores(N, s_star, mu_good, mu_bad, sigma, rng):\n",
    "    scores = rng.normal(loc=mu_bad, scale=sigma, size=N)\n",
    "    scores[s_star] = rng.normal(loc=mu_good, scale=sigma)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721802bf",
   "metadata": {},
   "source": [
    "## Confidence Metric\n",
    "\n",
    "We reuse the margin-based confidence proxy:\n",
    "\n",
    "- `margin = best - second_best`\n",
    "- `confidence = logistic(margin)`\n",
    "\n",
    "This yields a stable confidence curve that is easy to print and export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096a66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def confidence_from_margin(cumulative):\n",
    "    sorted_scores = np.sort(cumulative)\n",
    "    margin = sorted_scores[-1] - sorted_scores[-2]\n",
    "    return float(logistic(margin)), float(margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f984a1",
   "metadata": {},
   "source": [
    "## Quantum-Analogue Amplification Step\n",
    "\n",
    "In quantum amplitude amplification, probability mass is iteratively concentrated on the correct hypothesis.\n",
    "\n",
    "We model this numerically by applying a small \"amplification boost\" to the leading hypothesis\n",
    "each query, representing a quantum-enhanced step that accelerates certainty.\n",
    "\n",
    "This is not a hardware simulation. It is a threat-model abstraction:\n",
    "- classical: evidence accumulates linearly\n",
    "- quantum-enhanced: certainty concentrates faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0822cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplify(cumulative, strength=0.35):\n",
    "    \"\"\"\n",
    "    Numerical analogue of amplification:\n",
    "    increase separation between best candidate and others.\n",
    "    \"\"\"\n",
    "    best_idx = int(np.argmax(cumulative))\n",
    "    boosted = cumulative.copy()\n",
    "    boosted[best_idx] += strength * np.std(boosted)  # scale to problem difficulty\n",
    "    return boosted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43888b0f",
   "metadata": {},
   "source": [
    "## One Quantum-Enhanced Inference Run\n",
    "\n",
    "Process:\n",
    "1. Sample scores and accumulate as in classical inference.\n",
    "2. Apply amplification step (concentrate weight faster).\n",
    "3. Stop once confidence exceeds target.\n",
    "\n",
    "We record:\n",
    "- queries used\n",
    "- success vs true hidden state\n",
    "- final confidence and margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7025b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantum_enhanced_run(N, mu_good, mu_bad, sigma, rng,\n",
    "                         max_queries=200, target_confidence=0.95, amplify_strength=0.35):\n",
    "    s_star = int(rng.integers(0, N))\n",
    "    cumulative = np.zeros(N)\n",
    "    conf = 0.0\n",
    "    margin = 0.0\n",
    "    best_idx = 0\n",
    "    queries_used = 0\n",
    "\n",
    "    for t in range(1, max_queries + 1):\n",
    "        scores = sample_scores(N, s_star, mu_good, mu_bad, sigma, rng)\n",
    "        cumulative += scores\n",
    "\n",
    "        # Apply quantum-analogue amplification\n",
    "        cumulative = amplify(cumulative, strength=amplify_strength)\n",
    "\n",
    "        best_idx = int(np.argmax(cumulative))\n",
    "        conf, margin = confidence_from_margin(cumulative)\n",
    "        queries_used = t\n",
    "\n",
    "        if conf >= target_confidence:\n",
    "            break\n",
    "\n",
    "    success = (best_idx == s_star)\n",
    "    return {\n",
    "        \"success\": success,\n",
    "        \"queries_used\": queries_used,\n",
    "        \"confidence\": conf,\n",
    "        \"margin\": margin,\n",
    "        \"s_star\": s_star,\n",
    "        \"best_idx\": best_idx\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bacbde",
   "metadata": {},
   "source": [
    "## Batch Experiment and Report\n",
    "\n",
    "We run many trials and report:\n",
    "- success rate\n",
    "- median queries to target confidence\n",
    "- 90th percentile queries\n",
    "- fraction exceeding anomaly threshold\n",
    "\n",
    "This should show fewer queries than the classical baseline, meaning:\n",
    "- less interaction\n",
    "- less observable activity\n",
    "- higher stealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d2cc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Quantum-Enhanced Enumeration (Certainty Compression) ===\n",
      "Candidate states (N):                 128\n",
      "Signal separation (μ_good-μ_bad):     1.00\n",
      "Noise level (σ):                      1.00\n",
      "Target confidence:                    0.95\n",
      "Trials:                               200\n",
      "Amplification strength:               0.35\n",
      "\n",
      "Success rate:                         0.430\n",
      "Median queries to reach confidence:   6\n",
      "90th percentile queries:              10\n",
      "Anomaly threshold (queries):          80\n",
      "Fraction exceeding anomaly threshold: 0.000\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(trials):\n",
    "    r = quantum_enhanced_run(\n",
    "        N=N,\n",
    "        mu_good=mu_good,\n",
    "        mu_bad=mu_bad,\n",
    "        sigma=sigma,\n",
    "        rng=rng,\n",
    "        max_queries=max_queries,\n",
    "        target_confidence=target_confidence,\n",
    "        amplify_strength=amplify_strength\n",
    "    )\n",
    "    results.append(r)\n",
    "\n",
    "queries = np.array([r[\"queries_used\"] for r in results])\n",
    "successes = np.array([r[\"success\"] for r in results], dtype=int)\n",
    "\n",
    "success_rate = successes.mean()\n",
    "median_queries = int(np.median(queries))\n",
    "p90_queries = int(np.percentile(queries, 90))\n",
    "anomaly_rate = (queries > anomaly_query_threshold).mean()\n",
    "\n",
    "print(\"=== Quantum-Enhanced Enumeration (Certainty Compression) ===\")\n",
    "print(f\"Candidate states (N):                 {N}\")\n",
    "print(f\"Signal separation (μ_good-μ_bad):     {mu_good - mu_bad:.2f}\")\n",
    "print(f\"Noise level (σ):                      {sigma:.2f}\")\n",
    "print(f\"Target confidence:                    {target_confidence:.2f}\")\n",
    "print(f\"Trials:                               {trials}\")\n",
    "print(f\"Amplification strength:               {amplify_strength:.2f}\")\n",
    "print()\n",
    "print(f\"Success rate:                         {success_rate:.3f}\")\n",
    "print(f\"Median queries to reach confidence:   {median_queries}\")\n",
    "print(f\"90th percentile queries:              {p90_queries}\")\n",
    "print(f\"Anomaly threshold (queries):          {anomaly_query_threshold}\")\n",
    "print(f\"Fraction exceeding anomaly threshold: {anomaly_rate:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff21ca",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "If the median and 90th percentile query counts drop relative to the classical baseline, then:\n",
    "\n",
    "- the attacker reaches high certainty with fewer interactions\n",
    "- fewer retries are needed\n",
    "- behavioral detection thresholds are less likely to trigger\n",
    "- exploitation becomes quieter and faster\n",
    "\n",
    "This is the mechanism by which quantum-enhanced reasoning can make MOVEit-class attack chains more dangerous:\n",
    "not by changing the vulnerability, but by compressing uncertainty and reducing observable activity.\n",
    "\n",
    "Reference: Code Example 2 — Quantum-Enhanced Certainty Model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
